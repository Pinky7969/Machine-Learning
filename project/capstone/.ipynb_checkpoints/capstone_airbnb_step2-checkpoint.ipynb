{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is data preprocess explained in \"capstone_airbnb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime, date\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from IPython.display import display\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "import operator\n",
    "\n",
    "# Draw inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Set figure aesthetics\n",
    "sns.set_style(\"white\", {'ytick.major.size': 10.0})\n",
    "sns.set_context(\"poster\", font_scale=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_account_created</th>\n",
       "      <th>timestamp_first_active</th>\n",
       "      <th>date_first_booking</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>signup_method</th>\n",
       "      <th>signup_flow</th>\n",
       "      <th>language</th>\n",
       "      <th>affiliate_channel</th>\n",
       "      <th>affiliate_provider</th>\n",
       "      <th>first_affiliate_tracked</th>\n",
       "      <th>signup_app</th>\n",
       "      <th>first_device_type</th>\n",
       "      <th>first_browser</th>\n",
       "      <th>country_destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gxn3p5htnn</td>\n",
       "      <td>2010-06-28</td>\n",
       "      <td>20090319043255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>820tgsjxq7</td>\n",
       "      <td>2011-05-25</td>\n",
       "      <td>20090523174809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALE</td>\n",
       "      <td>38.0</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>seo</td>\n",
       "      <td>google</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4ft3gnwmtx</td>\n",
       "      <td>2010-09-28</td>\n",
       "      <td>20090609231247</td>\n",
       "      <td>2010-08-02</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>56.0</td>\n",
       "      <td>basic</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>IE</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bjjt8pjhuk</td>\n",
       "      <td>2011-12-05</td>\n",
       "      <td>20091031060129</td>\n",
       "      <td>2012-09-08</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>42.0</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87mebub9p4</td>\n",
       "      <td>2010-09-14</td>\n",
       "      <td>20091208061105</td>\n",
       "      <td>2010-02-18</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>41.0</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id date_account_created  timestamp_first_active date_first_booking  \\\n",
       "0  gxn3p5htnn           2010-06-28          20090319043255                NaN   \n",
       "1  820tgsjxq7           2011-05-25          20090523174809                NaN   \n",
       "2  4ft3gnwmtx           2010-09-28          20090609231247         2010-08-02   \n",
       "3  bjjt8pjhuk           2011-12-05          20091031060129         2012-09-08   \n",
       "4  87mebub9p4           2010-09-14          20091208061105         2010-02-18   \n",
       "\n",
       "      gender   age signup_method  signup_flow language affiliate_channel  \\\n",
       "0  -unknown-   NaN      facebook            0       en            direct   \n",
       "1       MALE  38.0      facebook            0       en               seo   \n",
       "2     FEMALE  56.0         basic            3       en            direct   \n",
       "3     FEMALE  42.0      facebook            0       en            direct   \n",
       "4  -unknown-  41.0         basic            0       en            direct   \n",
       "\n",
       "  affiliate_provider first_affiliate_tracked signup_app first_device_type  \\\n",
       "0             direct               untracked        Web       Mac Desktop   \n",
       "1             google               untracked        Web       Mac Desktop   \n",
       "2             direct               untracked        Web   Windows Desktop   \n",
       "3             direct               untracked        Web       Mac Desktop   \n",
       "4             direct               untracked        Web       Mac Desktop   \n",
       "\n",
       "  first_browser country_destination  \n",
       "0        Chrome                 NDF  \n",
       "1        Chrome                 NDF  \n",
       "2            IE                  US  \n",
       "3       Firefox               other  \n",
       "4        Chrome                  US  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_users_path = 'data/train_users_2.csv'\n",
    "test_users_path = 'data/test_users.csv'\n",
    "\n",
    "# Load the data into DataFrames\n",
    "\n",
    "# train_users\n",
    "train_users = pd.read_csv(train_users_path)\n",
    "\n",
    "# original training data\n",
    "display(train_users.head())\n",
    "\n",
    "target = train_users['country_destination']\n",
    "train_users = train_users.drop(['country_destination'], axis=1)\n",
    "\n",
    "# test_users\n",
    "test_users = pd.read_csv(test_users_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to Load from Checkpoint\n",
    "users = pd.read_pickle('users_checkpoint1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDCG Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "country_data = 'data/countries.csv'\n",
    "\n",
    "# Country Data\n",
    "data_contries = pd.read_csv(country_data)\n",
    "\n",
    "for idx in range(data_contries.shape[0]):\n",
    "    if data_contries['lng_destination'][idx] < 0:\n",
    "        data_contries['lng_destination'][idx] = 360+data_contries['lng_destination'][idx]\n",
    "\n",
    "dictLat={};\n",
    "dictLng={};\n",
    "for idx in range(data_contries.shape[0]):\n",
    "    dictLat[data_contries['country_destination'][idx]] = data_contries['lat_destination'][idx]\n",
    "    dictLng[data_contries['country_destination'][idx]] = data_contries['lng_destination'][idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGain(target, pred):\n",
    "    if target in dictLat:\n",
    "        tar_lat = dictLat[target]\n",
    "        tar_lng = dictLng[target]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    if pred in dictLat:\n",
    "        pred_lat = dictLat[pred]\n",
    "        pred_lng = dictLng[pred]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    if abs(tar_lng-pred_lng) <= 20.0 and abs(tar_lat-pred_lat) <= 40.0:\n",
    "        return 3\n",
    "    elif abs(tar_lng-pred_lng) <= 40.0 and abs(tar_lat-pred_lat) <= 80.0:\n",
    "        return 2\n",
    "    elif abs(tar_lng-pred_lng) <= 60.0 and abs(tar_lat-pred_lat) <= 120.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def dcg_at_k(r, k, method=1):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k=5, method=1):\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max\n",
    "\n",
    "\n",
    "def score_predictions(preds, truth, n_modes=5):\n",
    "    \"\"\"\n",
    "    preds: pd.DataFrame\n",
    "      one row for each observation, one column for each prediction.\n",
    "      Columns are sorted from left to right descending in order of likelihood.\n",
    "    truth: pd.Series\n",
    "      one row for each obeservation.\n",
    "    \"\"\"\n",
    "    assert(len(preds)==len(truth))\n",
    "    r = pd.DataFrame(0, index=preds.index, columns=preds.columns, dtype=np.float64)\n",
    "    #print truth\n",
    "    for row in np.arange(preds.shape[0]):\n",
    "        target=truth[row]\n",
    "        for col in preds.columns:\n",
    "            #print preds[col][row]\n",
    "            r[col][row] = getGain(target,preds[col][row])\n",
    "    \n",
    "    score = pd.Series(r.apply(ndcg_at_k, axis=1, reduce=True), name='score')\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Metrics to compute the model performance.\"\"\"\n",
    "# ref: https://www.kaggle.com/davidgasquez/airbnb-recruiting-new-user-bookings/ndcg-scorer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    "    \"\"\"Discounted cumulative gain (DCG) at rank K.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape = [n_samples]\n",
    "        Ground truth (true relevance labels).\n",
    "    y_score : array, shape = [n_samples, n_classes]\n",
    "        Predicted scores.\n",
    "    k : int\n",
    "        Rank.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "\n",
    "    gain = 2 ** y_true - 1\n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "def ndcg_score(ground_truth, predictions, k=5):\n",
    "    \"\"\"Normalized discounted cumulative gain (NDCG) at rank K.\n",
    "\n",
    "    Normalized Discounted Cumulative Gain (NDCG) measures the performance of a\n",
    "    recommendation system based on the graded relevance of the recommended\n",
    "    entities. It varies from 0.0 to 1.0, with 1.0 representing the ideal\n",
    "    ranking of the entities.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ground_truth : array, shape = [n_samples]\n",
    "        Ground truth (true labels represended as integers).\n",
    "    predictions : array, shape = [n_samples, n_classes]\n",
    "        Predicted probabilities.\n",
    "    k : int\n",
    "        Rank.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> ground_truth = [1, 0, 2]\n",
    "    >>> predictions = [[0.15, 0.55, 0.2], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "    >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "    1.0\n",
    "    >>> predictions = [[0.9, 0.5, 0.8], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "    >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "    0.6666666666\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    #lb.fit(range(len(predictions) + 1))  ## original\n",
    "    #lb.fit(range(predictions.shape[1] + 1))\n",
    "    #T = lb.transform(ground_truth)\n",
    "    \n",
    "    T = lb.fit_transform(ground_truth) \n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Iterate over each y_true and compute the DCG score\n",
    "    for y_true, y_score in zip(T, predictions):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)\n",
    "        score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# NDCG Scorer function\n",
    "ndcg_scorer = make_scorer(ndcg_score, needs_proba=True, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.630929753571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:59: FutureWarning: The reduce argument is deprecated and will be removed in a future version. You can specify result_type='reduce' to try to reduce the result to the original dimensions\n"
     ]
    }
   ],
   "source": [
    "preds = pd.DataFrame([['US','FR']])\n",
    "truth = pd.Series(['FR'])\n",
    "\n",
    "print score_predictions(preds, truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  7 10 ...  7  7  7]\n"
     ]
    }
   ],
   "source": [
    "# Create numeric label for each of the 12 target labels\n",
    "labels = target.values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data back into train and test sets\n",
    "vals = users.values\n",
    "piv_train = len(target)\n",
    "X = vals[:piv_train]\n",
    "X_test = vals[piv_train:]\n",
    "\n",
    "# Create numeric label for each of the 12 target labels\n",
    "labels = target.values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
       "            oob_score=False, random_state=101, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': [2, 20], 'max_depth': [6, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring=make_scorer(ndcg_score, needs_proba=True, k=5), verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import grid_search\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=25, random_state=101)\n",
    "parameters = {'min_samples_split': [2, 20],\n",
    "              'max_depth': [6, 8]\n",
    "             }\n",
    "\n",
    "reg = grid_search.GridSearchCV(clf, parameters, scoring=ndcg_scorer, cv=3)\n",
    "\n",
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=20,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1,\n",
       "            oob_score=False, random_state=101, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = reg.best_estimator_\n",
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = est.predict_proba(X)\n",
    "if len(y) > 0:\n",
    "    truth = pd.Series(le.inverse_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = est.predict_proba(X)\n",
    "\n",
    "truth = pd.Series(le.inverse_transform(y))\n",
    "preds = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    preds += [le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()]\n",
    "\n",
    "preds = pd.DataFrame(preds)\n",
    "print \"Score for Random Forrest: \" + str(score_predictions(preds, truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
